# ğŸ“Š Flink Aggregation - MÃ³dulo de AgregaÃ§Ã£o de Vendas

Este mÃ³dulo implementa processamento em tempo real de eventos de vendas usando Apache Flink, calculando agregaÃ§Ãµes como valor total de vendas.

## ğŸ“‹ DescriÃ§Ã£o

O mÃ³dulo `flink-aggregation` Ã© responsÃ¡vel por:

- **Consumir eventos de vendas** do tÃ³pico Kafka "sales"
- **Processar em tempo real** usando Apache Flink
- **Agregar valores totais** de vendas em janelas de tempo
- **Exibir resultados** de agregaÃ§Ã£o no console

## ğŸ—ï¸ Componentes

### ğŸ“¦ Model (`model/`)

#### `Sale.java`
- Representa um evento de venda recebido do Kafka
- ContÃ©m ID da venda, vendedor e lista de itens
- MÃ©todo `getTotalValue()` calcula valor total da venda

#### `SaleItem.java`  
- Representa um item individual dentro de uma venda
- ContÃ©m ID do produto, quantidade e valor

#### `SalesAggregation.java`
- Modelo de agregaÃ§Ã£o que acumula estatÃ­sticas
- Campos: total de vendas, valor total, timestamp da Ãºltima atualizaÃ§Ã£o
- MÃ©todos para combinar agregaÃ§Ãµes

### âš™ï¸ Processor (`processor/`)

#### `SalesAggregationProcessor.java`
- Implementa `AggregateFunction` do Flink
- Define como agregar eventos de vendas
- OperaÃ§Ãµes: criar acumulador, adicionar venda, mesclar agregaÃ§Ãµes

### ğŸš€ Job (`job/`)

#### `SalesAggregationJob.java`
- **Classe principal** do job Flink
- Configura fonte Kafka e pipeline de processamento
- Define janelas de agregaÃ§Ã£o (30 segundos)
- Converte JSON para objetos Sale

## ğŸ”§ ConfiguraÃ§Ã£o

### ParÃ¢metros do Kafka
- **Servidores**: `localhost:9092`
- **TÃ³pico**: `sales`
- **Grupo de consumidor**: `flink-sales-aggregation`

### Janelas de AgregaÃ§Ã£o
- **Tipo**: Tumbling Windows (janelas fixas)
- **DuraÃ§Ã£o**: 30 segundos
- **Processamento**: Processing Time

## ğŸš€ ExecuÃ§Ã£o

### PrÃ©-requisitos
1. **Flink instalado** e cluster rodando em `localhost:8081`
2. **Kafka rodando** com tÃ³pico `sales`
3. **Producer de vendas** executando

### Executar Job
```bash
# Script automatizado
./run-flink-job.sh
```

### Manual
```bash
# Compilar o projeto
mvn clean package

# Submeter para cluster Flink
flink run -c com.crisaltmann.flinkcountsales.aggregation.job.SalesAggregationJob \
  target/flink-aggregation-0.0.1-SNAPSHOT.jar
```

## ğŸ“Š Output

O job exibe resultados no console a cada janela de 30 segundos:

```
SalesAggregation(totalSalesCount=5, totalSalesValue=150.50, lastUpdated=1703123456789)
```

Onde:
- `totalSalesCount`: NÃºmero total de vendas na janela
- `totalSalesValue`: Valor total em reais das vendas
- `lastUpdated`: Timestamp da Ãºltima atualizaÃ§Ã£o

## ğŸ› ï¸ Tecnologias

- â˜• **Java 17**
- ğŸŒŠ **Apache Flink 1.18.0** - Stream processing
- ğŸ“¡ **Flink Kafka Connector** - IntegraÃ§Ã£o com Kafka
- ğŸ”§ **Lombok** - ReduÃ§Ã£o de boilerplate
- ğŸ“ **Jackson** - Processamento JSON
- ğŸ“‹ **Log4j2** - Sistema de logs

## ğŸ”— DependÃªncias

Este mÃ³dulo funciona em conjunto com:
- `sales-producer`: Gera eventos de vendas para o Kafka
- Kafka: Broker de mensagens para streaming de eventos

## âš¡ Performance

- **LatÃªncia**: Baixa latÃªncia com processamento em streaming
- **Throughput**: Suporta alto volume de eventos
- **Paralelismo**: ConfigurÃ¡vel via Flink
- **TolerÃ¢ncia a falhas**: Checkpointing automÃ¡tico do Flink